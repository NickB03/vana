#!/usr/bin/env python3
"""
Direct model test for Gemini 2.5 Flash model (Phase 3).

This script directly tests the model changes without loading the full app.
"""

import os
import sys
import asyncio
from pathlib import Path

# Load environment variables
env_local_path = Path(__file__).parent.parent / ".env.local"
if env_local_path.exists():
    with open(env_local_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key] = value

# Add the app directory to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import google.generativeai as genai
    from app.models import CRITIC_MODEL, WORKER_MODEL
except ImportError as e:
    print(f"‚ùå Error importing required modules: {e}")
    sys.exit(1)


def test_model_constants():
    """Test that model constants are updated correctly."""
    print("üîß Testing model constants...")

    print(f"CRITIC_MODEL: {CRITIC_MODEL}")
    print(f"WORKER_MODEL: {WORKER_MODEL}")

    # Verify models are updated to Gemini 2.5 Flash
    expected_model = "models/gemini-2.0-flash-exp"
    if CRITIC_MODEL == expected_model and WORKER_MODEL == expected_model:
        print("‚úÖ Model constants updated correctly")
        return True
    else:
        print(f"‚ùå Model constants not updated. Expected: {expected_model}")
        return False


async def test_direct_model_usage():
    """Test direct model usage with the updated constants."""
    print("\nü§ñ Testing direct model usage...")

    try:
        # Configure genai
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("‚ùå GOOGLE_API_KEY not available")
            return False

        genai.configure(api_key=api_key)

        # Test both critic and worker models
        models_to_test = [
            ("CRITIC_MODEL", CRITIC_MODEL),
            ("WORKER_MODEL", WORKER_MODEL)
        ]

        for model_name, model_id in models_to_test:
            print(f"\nTesting {model_name}: {model_id}")

            try:
                model = genai.GenerativeModel(model_id)

                # Test async generation (same pattern as in research_agents.py)
                response = await asyncio.to_thread(
                    model.generate_content,
                    f"Test prompt for {model_name}: What is machine learning?",
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        top_p=0.8,
                        top_k=40,
                        max_output_tokens=200,
                    ),
                )

                # Test response parsing (same logic as in research_agents.py)
                content = ""
                if hasattr(response, 'text') and response.text:
                    content = response.text
                elif hasattr(response, "candidates") and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, "content") and candidate.content.parts:
                        content = candidate.content.parts[0].text

                if content:
                    print(f"‚úÖ {model_name} generated {len(content)} characters")
                    print(f"Preview: {content[:80]}...")
                else:
                    print(f"‚ö†Ô∏è  {model_name} generated empty response")

            except Exception as e:
                print(f"‚ùå {model_name} failed: {e}")
                return False

        print("\n‚úÖ All models tested successfully")
        return True

    except Exception as e:
        print(f"‚ùå Direct model test failed: {e}")
        return False


async def test_error_handling_patterns():
    """Test error handling patterns from research_agents.py."""
    print("\nüõ°Ô∏è Testing error handling patterns...")

    try:
        api_key = os.getenv("GOOGLE_API_KEY")
        genai.configure(api_key=api_key)

        # Test with valid model but potentially problematic prompt
        model = genai.GenerativeModel(WORKER_MODEL)

        test_cases = [
            ("Normal prompt", "What is Python programming?"),
            ("Empty prompt", ""),
            ("Very long prompt", "A" * 1000 + " What is this?")
        ]

        for test_name, prompt in test_cases:
            print(f"\nTesting: {test_name}")
            try:
                if not prompt:  # Skip empty prompt test
                    print("  ‚ö†Ô∏è  Skipping empty prompt test")
                    continue

                response = await asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        max_output_tokens=100,
                    ),
                )

                # Use the same parsing logic as updated research_agents.py
                content = ""
                if hasattr(response, 'text') and response.text:
                    content = response.text
                elif hasattr(response, "candidates") and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, "content") and candidate.content.parts:
                        content = candidate.content.parts[0].text
                    else:
                        finish_reason = getattr(candidate, 'finish_reason', None)
                        if finish_reason and 'SAFETY' in str(finish_reason):
                            content = f"Response filtered by safety guidelines. Finish reason: {finish_reason}"
                        else:
                            content = f"Empty response. Finish reason: {finish_reason}"

                print(f"  ‚úÖ Handled successfully: {len(content)} chars")

            except Exception as e:
                error_msg = str(e).lower()
                if "quota" in error_msg or "rate limit" in error_msg:
                    print(f"  ‚úÖ Quota/rate limit error handled: {type(e).__name__}")
                elif "api key" in error_msg or "authentication" in error_msg:
                    print(f"  ‚úÖ Auth error handled: {type(e).__name__}")
                elif "safety" in error_msg or "blocked" in error_msg:
                    print(f"  ‚úÖ Safety error handled: {type(e).__name__}")
                else:
                    print(f"  ‚úÖ General error handled: {type(e).__name__}: {e}")

        return True

    except Exception as e:
        print(f"‚ùå Error handling test failed: {e}")
        return False


async def main():
    """Main test function."""
    print("üß™ Direct Gemini 2.5 Flash Model Test")
    print("=" * 50)

    success_count = 0
    total_tests = 3

    # Test 1: Model Constants
    if test_model_constants():
        success_count += 1

    # Test 2: Direct Model Usage
    if await test_direct_model_usage():
        success_count += 1

    # Test 3: Error Handling
    if await test_error_handling_patterns():
        success_count += 1

    print("\n" + "=" * 50)
    print(f"üìä Test Results: {success_count}/{total_tests} tests passed")

    if success_count == total_tests:
        print("üéâ All tests passed! Model migration is working correctly!")
        return True
    else:
        print(f"‚ö†Ô∏è  {total_tests - success_count} tests failed.")
        return False


if __name__ == "__main__":
    try:
        result = asyncio.run(main())
        sys.exit(0 if result else 1)
    except KeyboardInterrupt:
        print("\nüõë Test interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\nüí• Unexpected error: {e}")
        sys.exit(1)