# GLM Migration - System Architecture

**Last Updated**: 2025-12-01
**Migration Status**: Phase 4 Complete (SSE Streaming Implementation)

## Overview

The GLM migration introduces a dual-provider architecture with intelligent routing between GLM (primary) and OpenRouter (fallback) for chat requests.

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                        â”‚
â”‚                    ChatInterface Component                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    POST /chat (streaming)
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Supabase Edge Function: chat/                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              GLM Chat Router (NEW)                       â”‚  â”‚
â”‚  â”‚         supabase/functions/_shared/glm-chat-router.ts   â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚        Circuit Breaker State                   â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - consecutiveFailures: number                â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - circuitOpenUntil: timestamp                â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - THRESHOLD: 3 failures                      â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  - RESET: 60 seconds                          â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Routing Logic:                                          â”‚  â”‚
â”‚  â”‚  1. Check circuit breaker status                         â”‚  â”‚
â”‚  â”‚  2. If OPEN â†’ route to OpenRouter                        â”‚  â”‚
â”‚  â”‚  3. If CLOSED â†’ try GLM first                            â”‚  â”‚
â”‚  â”‚  4. On GLM failure â†’ fallback to OpenRouter              â”‚  â”‚
â”‚  â”‚  5. Track failures for circuit management                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                   â”‚                      â”‚
â”‚              GLM Success          GLM Failure                  â”‚
â”‚                     â”‚                   â”‚                      â”‚
â”‚                     â–¼                   â–¼                      â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚          â”‚ GLM Client       â”‚  â”‚ OpenRouter Clientâ”‚           â”‚
â”‚          â”‚ (glm-client.ts)  â”‚  â”‚ (openrouter-     â”‚           â”‚
â”‚          â”‚                  â”‚  â”‚  client.ts)      â”‚           â”‚
â”‚          â”‚ - Retry logic    â”‚  â”‚                  â”‚           â”‚
â”‚          â”‚ - Token tracking â”‚  â”‚ - Gemini Flash   â”‚           â”‚
â”‚          â”‚ - Cost logging   â”‚  â”‚ - Retry logic    â”‚           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                   â”‚                     â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                     â”‚
                    â–¼                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Z.ai GLM API    â”‚  â”‚  OpenRouter API    â”‚
        â”‚   (GLM-4.6)       â”‚  â”‚  (Gemini Flash)    â”‚
        â”‚                   â”‚  â”‚                    â”‚
        â”‚ - Coding Plan     â”‚  â”‚ - Unlimited key    â”‚
        â”‚ - Thinking mode   â”‚  â”‚ - Fast responses   â”‚
        â”‚ - Streaming       â”‚  â”‚ - Streaming        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Request Flow Diagrams

### Normal Operation (Circuit CLOSED)

```
User Message
    â”‚
    â–¼
Chat Edge Function
    â”‚
    â–¼
GLM Chat Router
    â”‚
    â”œâ”€ Check circuit: CLOSED âœ“
    â”‚
    â–¼
Try GLM API
    â”‚
    â”œâ”€ Success? YES âœ“
    â”‚
    â”œâ”€ Reset failure counter
    â”‚
    â–¼
Stream response to user
```

### Fallback Scenario (GLM Failure)

```
User Message
    â”‚
    â–¼
Chat Edge Function
    â”‚
    â–¼
GLM Chat Router
    â”‚
    â”œâ”€ Check circuit: CLOSED âœ“
    â”‚
    â–¼
Try GLM API
    â”‚
    â”œâ”€ Success? NO âœ—
    â”‚
    â”œâ”€ Status: 429 (Rate Limited)
    â”‚
    â”œâ”€ Retries: 0/2, 1/2, 2/2 â†’ All fail
    â”‚
    â”œâ”€ Classify error: RETRYABLE âœ“
    â”‚
    â”œâ”€ Increment failure counter (1 â†’ 2 â†’ 3)
    â”‚
    â–¼
Fallback to OpenRouter
    â”‚
    â”œâ”€ Call Gemini Flash API
    â”‚
    â”œâ”€ Success? YES âœ“
    â”‚
    â–¼
Stream response to user
```

### Circuit Breaker Opens

```
User Message (after 3 failures)
    â”‚
    â–¼
Chat Edge Function
    â”‚
    â–¼
GLM Chat Router
    â”‚
    â”œâ”€ Check circuit: OPEN âš ï¸
    â”‚
    â”œâ”€ Skip GLM entirely
    â”‚
    â–¼
Route directly to OpenRouter
    â”‚
    â”œâ”€ Call Gemini Flash API
    â”‚
    â”œâ”€ Success? YES âœ“
    â”‚
    â–¼
Stream response to user
    â”‚
    â””â”€ After 60s: Circuit auto-resets to CLOSED
```

## SSE Streaming Architecture (Phase 4)

### Artifact Generation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React)                              â”‚
â”‚                                                                  â”‚
â”‚  useChatMessages.tsx                   ReasoningDisplay.tsx      â”‚
â”‚  â”œâ”€ EventSource connection             â”œâ”€ Claude-style ticker    â”‚
â”‚  â”œâ”€ reasoning_chunk handler    â”€â”€â”€â–º    â”œâ”€ Live status updates    â”‚
â”‚  â”œâ”€ content_chunk handler              â”œâ”€ Timer display          â”‚
â”‚  â””â”€ artifact_complete handler          â””â”€ Expandable reasoning   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              GET /generate-artifact?stream=true
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Edge Function: generate-artifact/                      â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              SSE Stream Controller                        â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  GLM API Response       SSE Events                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ reasoning_ â”‚ â”€â”€â”€â–º   â”‚ event: reasoning_chunk      â”‚    â”‚   â”‚
â”‚  â”‚  â”‚ content    â”‚        â”‚ data: "Let me analyze..."   â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚ content    â”‚ â”€â”€â”€â–º   â”‚ event: content_chunk        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚            â”‚        â”‚ data: "export default..."   â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  On Complete â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ event: artifact_complete    â”‚    â”‚   â”‚
â”‚  â”‚                        â”‚ data: {artifact JSON}       â”‚    â”‚   â”‚
â”‚  â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SSE Event Types

| Event Type | Data Format | Description |
|------------|-------------|-------------|
| `reasoning_chunk` | string | Incremental GLM thinking text |
| `reasoning_complete` | string | Full reasoning text (end marker) |
| `content_chunk` | string | Incremental artifact code |
| `artifact_complete` | JSON | Full artifact with metadata |
| `error` | JSON | Error details on failure |

### Key Implementation Files

| File | Purpose |
|------|---------|
| `generate-artifact/index.ts` | SSE stream controller, GLM integration |
| `useChatMessages.tsx` | EventSource setup, event handlers |
| `ReasoningDisplay.tsx` | Claude-style ticker pill component |
| `glm-reasoning-parser.ts` | Incremental parsing for live updates |

---

## Component Responsibilities

### `glm-chat-router.ts` (NEW)

**Responsibilities**:
- Provider selection (GLM vs OpenRouter)
- Circuit breaker management
- Error classification
- Fallback orchestration
- Message format conversion

**Exports**:
- `routeChatRequest(messages, options)` - Main routing function
- `getCircuitBreakerStatus()` - Status monitoring
- `resetCircuitBreaker()` - Manual reset

**State**:
- `consecutiveFailures: number` - Failure counter
- `circuitOpenUntil: timestamp` - Circuit timeout

### `glm-client.ts` (Existing)

**Responsibilities**:
- GLM API communication
- Retry logic (exponential backoff)
- Token usage tracking
- Cost calculation
- Streaming support

**Key Functions**:
- `callGLMWithRetry()` - Main GLM call with retries
- `extractTextAndReasoningFromGLM()` - Parse responses
- `processGLMStream()` - Handle SSE streaming

### `openrouter-client.ts` (Existing)

**Responsibilities**:
- OpenRouter API communication
- Gemini Flash model access
- Retry logic
- Token tracking

**Key Functions**:
- `callGeminiFlashWithRetry()` - Main Gemini Flash call
- `extractTextFromGeminiFlash()` - Parse responses

## Error Handling Strategy

### Error Classification

```
API Error Response
    â”‚
    â–¼
Check Status Code
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                 â”‚
    â–¼                                 â–¼
RETRYABLE                      NON-RETRYABLE
- 429 Rate Limited             - 400 Bad Request
- 503 Service Unavailable      - 401 Unauthorized
    â”‚                                 â”‚
    â–¼                                 â–¼
Retry with backoff             Return error immediately
    â”‚                          (no fallback)
    â”œâ”€ Success? YES â†’ Done
    â”‚
    â”œâ”€ Max retries? NO â†’ Retry again
    â”‚
    â”œâ”€ Max retries? YES
    â”‚
    â–¼
Fallback to OpenRouter
```

### Circuit Breaker Thresholds

| Metric | Value | Rationale |
|--------|-------|-----------|
| Failure Threshold | 3 | Quick detection without false positives |
| Reset Timeout | 60s | Balance between recovery and availability |
| Retry Attempts | 2 | Exponential backoff (1s, 2s, 4s) |

## Migration Phases

### âœ… Phase 1: GLM Client (Complete)
- [x] Create `glm-client.ts`
- [x] Implement retry logic
- [x] Add streaming support
- [x] Token tracking & cost calculation

### âœ… Phase 2: Testing Infrastructure (Complete)
- [x] Unit tests for GLM client
- [x] Mock API responses
- [x] Streaming tests
- [x] Error handling tests

### âœ… Phase 3: Router Implementation (Complete)
- [x] Create `glm-chat-router.ts`
- [x] Circuit breaker pattern
- [x] Error classification
- [x] Message format conversion
- [x] Comprehensive documentation

### âœ… Phase 4: SSE Streaming Implementation (Complete - 2025-12-01)
- [x] Replace parallel dual-endpoint approach with single SSE stream
- [x] Implement `reasoning_chunk`, `content_chunk` SSE event types
- [x] Add Claude-style ticker pill UI (`ReasoningDisplay.tsx`)
- [x] Fix artifact code appearing in chat during generation
- [x] Add incremental reasoning parser (`glm-reasoning-parser.ts`)
- [x] Implement stop button for stream cancellation
- [x] Add JSON fallback for backward compatibility

### ðŸš§ Phase 5: Production Optimization (Next)
- [ ] Add provider/fallback metrics
- [ ] Update admin dashboard with streaming analytics
- [ ] Add circuit breaker monitoring
- [ ] Performance benchmarking

### ðŸ“‹ Phase 6: Production Rollout (Future)
- [ ] Gradual rollout (10% â†’ 50% â†’ 100%)
- [ ] Monitor error rates
- [ ] Track cost savings
- [ ] User feedback collection

## Monitoring & Observability

### Metrics to Track

1. **Provider Distribution**
   - GLM requests: count
   - OpenRouter requests: count
   - Fallback ratio: %

2. **Circuit Breaker Activity**
   - Opens per day: count
   - Average duration: seconds
   - Failure patterns: timeline

3. **Performance**
   - GLM latency: p50, p95, p99
   - OpenRouter latency: p50, p95, p99
   - Fallback overhead: milliseconds

4. **Cost**
   - GLM cost per request: $
   - OpenRouter cost per request: $
   - Total savings: $ vs all-OpenRouter

### Dashboard Queries

```sql
-- Provider health over time
SELECT
  DATE_TRUNC('hour', created_at) as hour,
  provider,
  COUNT(*) as requests,
  AVG(latency_ms) as avg_latency,
  SUM(CASE WHEN status_code = 200 THEN 1 ELSE 0 END)::float / COUNT(*) * 100 as success_rate
FROM ai_usage_logs
WHERE function_name = 'chat'
  AND created_at > NOW() - INTERVAL '24 hours'
GROUP BY hour, provider
ORDER BY hour DESC;
```

```sql
-- Circuit breaker events
SELECT
  created_at,
  circuit_state,
  consecutive_failures,
  provider_used
FROM circuit_breaker_logs
WHERE created_at > NOW() - INTERVAL '7 days'
ORDER BY created_at DESC;
```

## Configuration

### Environment Variables

```bash
# GLM API Key (Z.ai Coding Plan)
GLM_API_KEY=sk-...

# OpenRouter Keys
OPENROUTER_GEMINI_FLASH_KEY=sk-or-v1-...

# Router Configuration (optional overrides)
CIRCUIT_BREAKER_THRESHOLD=3        # Failures before opening
CIRCUIT_BREAKER_RESET_MS=60000     # Time before auto-close
RETRY_MAX_ATTEMPTS=2               # Max retries per request
```

### Code Constants

Located in `glm-chat-router.ts`:

```typescript
const CIRCUIT_THRESHOLD = 3;
const CIRCUIT_RESET_MS = 60000;
```

Located in `config.ts`:

```typescript
export const RETRY_CONFIG = {
  MAX_RETRIES: 2,
  BACKOFF_MULTIPLIER: 2,
  INITIAL_DELAY_MS: 1000,
  MAX_DELAY_MS: 10000
};
```

## Cost Analysis

### Model Pricing (per 1M tokens)

| Provider | Model | Input | Output |
|----------|-------|-------|--------|
| Z.ai | GLM-4.6 | $0.10 | $0.30 |
| OpenRouter | Gemini Flash | $0.075 | $0.30 |

### Estimated Savings

Assuming:
- 80% of requests succeed with GLM
- 20% fallback to OpenRouter
- Average: 100 input tokens, 500 output tokens per request

**Cost per 1000 requests**:
- All GLM: $0.16
- All OpenRouter: $0.16
- Mixed (80/20): ~$0.16 (similar cost, better reliability)

**Key Benefit**: Not cost savings, but **improved reliability** through redundancy.

## Testing Strategy

### Unit Tests
- [x] Circuit breaker state management
- [x] Error classification logic
- [ ] Message format conversion
- [ ] Provider selection logic

### Integration Tests
- [ ] GLM â†’ OpenRouter fallback flow
- [ ] Circuit breaker open/close cycle
- [ ] Streaming response handling
- [ ] Concurrent request handling

### Load Tests
- [ ] Circuit breaker under high failure rate
- [ ] Fallback performance at scale
- [ ] Memory usage under load
- [ ] State consistency across instances

## Related Documentation

- [GLM Chat Router Guide](./GLM-CHAT-ROUTER.md) - Detailed router documentation
- [GLM-4.6 Capabilities](./GLM-4.6-CAPABILITIES.md) - Model capabilities and API
- [Migration Plan](./GLM-MIGRATION-PLAN.md) - Overall migration strategy

## See Also

- **Code**: `supabase/functions/_shared/glm-chat-router.ts`
- **Tests**: `supabase/functions/_shared/__tests__/glm-chat-router.test.ts`
- **Dependencies**: `glm-client.ts`, `openrouter-client.ts`, `config.ts`
