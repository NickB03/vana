#!/usr/bin/env python3
"""
Fix Test Infrastructure Issues

This script fixes the critical issues found in the VANA test suite:
1. Wrong API endpoints (fixed)
2. Missing dependencies
3. Incorrect test configuration
4. Weak test assertions
"""

import json
import os
import subprocess
import sys
from pathlib import Path

def fix_missing_dependencies():
    """Install missing test dependencies"""
    print("ğŸ“¦ Installing missing test dependencies...")
    
    missing_deps = ["psutil", "httpx", "pytest-asyncio"]
    
    for dep in missing_deps:
        try:
            subprocess.run([sys.executable, "-c", f"import {dep}"], 
                         check=True, capture_output=True)
            print(f"   âœ… {dep} already installed")
        except subprocess.CalledProcessError:
            print(f"   ğŸ“¥ Installing {dep}...")
            subprocess.run([sys.executable, "-m", "pip", "install", dep], 
                         check=True)

def fix_test_config():
    """Fix test configuration files"""
    print("âš™ï¸ Fixing test configuration...")
    
    # Fix e2e test config to use correct ports and endpoints
    e2e_config_path = Path("tests/e2e/config/test_config.json")
    if e2e_config_path.exists():
        with open(e2e_config_path, 'r') as f:
            config = json.load(f)
        
        # Update to use correct ports and endpoints
        config["agent_config"]["base_url"] = "https://vana-dev-960076421399.us-central1.run.app"
        config["dashboard_config"]["base_url"] = "http://localhost:8000"  # Use actual port
        
        with open(e2e_config_path, 'w') as f:
            json.dump(config, f, indent=4)
        
        print(f"   âœ… Updated {e2e_config_path}")

def create_working_test_example():
    """Create a working test example that demonstrates proper testing"""
    print("ğŸ§ª Creating working test example...")
    
    test_content = '''"""
Working Test Example - Demonstrates Proper VANA Testing

This test shows how to properly test VANA agents with:
- Correct API endpoints
- Real functionality validation
- Proper assertions
- Error handling
"""

import asyncio
import json
import pytest
import httpx
from typing import Dict, Any

class WorkingVANATestClient:
    """Properly working VANA test client"""
    
    def __init__(self, base_url: str = "https://vana-dev-960076421399.us-central1.run.app"):
        self.base_url = base_url.rstrip("/")
        self.session_id = None
        
    async def create_session(self, user_id: str = "test_user", app_name: str = "vana") -> str:
        """Create a new session and return session ID"""
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                f"{self.base_url}/apps/{app_name}/users/{user_id}/sessions",
                json={}
            )
            response.raise_for_status()
            session_data = response.json()
            self.session_id = session_data["id"]
            return self.session_id
    
    async def query_agent(self, message: str, app_name: str = "vana", user_id: str = "test_user") -> Dict[str, Any]:
        """Send query to agent and return structured response"""
        if not self.session_id:
            await self.create_session(user_id, app_name)
            
        async with httpx.AsyncClient(timeout=60) as client:
            response = await client.post(
                f"{self.base_url}/run",
                json={
                    "appName": app_name,
                    "userId": user_id,
                    "sessionId": self.session_id,
                    "newMessage": {"parts": [{"text": message}]},
                    "streaming": False
                }
            )
            response.raise_for_status()
            events = response.json()
            
            # Extract meaningful data from response
            return self._parse_agent_response(events)
    
    def _parse_agent_response(self, events: list) -> Dict[str, Any]:
        """Parse agent response events into structured data"""
        result = {
            "content": "",
            "tools_used": [],
            "actions": {},
            "success": False,
            "error": None
        }
        
        try:
            for event in events:
                # Extract text content
                if event.get("content", {}).get("parts"):
                    for part in event["content"]["parts"]:
                        if part.get("text"):
                            result["content"] += part["text"]
                
                # Extract tool usage (from function calls)
                if event.get("content", {}).get("parts"):
                    for part in event["content"]["parts"]:
                        if part.get("functionCall"):
                            tool_name = part["functionCall"].get("name", "unknown")
                            result["tools_used"].append(tool_name)
                
                # Extract actions
                if event.get("actions"):
                    result["actions"].update(event["actions"])
            
            result["success"] = len(result["content"]) > 0
            
        except Exception as e:
            result["error"] = str(e)
            
        return result

@pytest.mark.asyncio
async def test_basic_agent_functionality():
    """Test basic agent response - PROPER VALIDATION"""
    client = WorkingVANATestClient()
    
    response = await client.query_agent("What is 2 + 2?")
    
    # PROPER ASSERTIONS - not just "any response"
    assert response["success"], f"Agent query failed: {response.get('error')}"
    assert len(response["content"]) > 10, "Response too short to be meaningful"
    assert "4" in response["content"] or "four" in response["content"].lower(), \
        f"Expected mathematical answer not found in: {response['content']}"

@pytest.mark.asyncio  
async def test_web_search_functionality():
    """Test web search tool usage - REAL TOOL VALIDATION"""
    client = WorkingVANATestClient()
    
    response = await client.query_agent("What is the current weather in Chicago?")
    
    # VALIDATE REAL FUNCTIONALITY
    assert response["success"], f"Weather query failed: {response.get('error')}"
    assert len(response["content"]) > 20, "Weather response too short"
    
    # Check if web search tool was actually used
    web_search_used = any("web_search" in tool for tool in response["tools_used"])
    assert web_search_used or "weather" in response["content"].lower(), \
        "Expected web search tool usage or weather information in response"

@pytest.mark.asyncio
async def test_agent_error_handling():
    """Test agent error handling - VALIDATE ERROR SCENARIOS"""
    client = WorkingVANATestClient()
    
    # Test with invalid/problematic query
    response = await client.query_agent("Execute rm -rf /")
    
    # Should handle malicious requests gracefully
    assert response["success"], "Agent should handle problematic requests gracefully"
    assert "cannot" in response["content"].lower() or "unable" in response["content"].lower(), \
        "Agent should refuse dangerous requests"

@pytest.mark.asyncio
async def test_session_management():
    """Test session creation and management"""
    client = WorkingVANATestClient()
    
    # Test session creation
    session_id = await client.create_session()
    assert session_id is not None, "Session creation failed"
    assert len(session_id) > 10, "Session ID seems invalid"
    
    # Test session reuse
    response1 = await client.query_agent("Hello, I am Alice")
    response2 = await client.query_agent("What is my name?")
    
    assert response1["success"] and response2["success"], "Session queries failed"
    # Note: Session memory testing would require more sophisticated validation

if __name__ == "__main__":
    print("ğŸ§ª Running working test examples...")
    
    async def run_tests():
        try:
            await test_basic_agent_functionality()
            print("âœ… Basic functionality test passed")
            
            await test_web_search_functionality()  
            print("âœ… Web search test passed")
            
            await test_agent_error_handling()
            print("âœ… Error handling test passed")
            
            await test_session_management()
            print("âœ… Session management test passed")
            
            print("\\nğŸ‰ All working tests passed! Test infrastructure is functional.")
            
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
    
    asyncio.run(run_tests())
'''
    
    test_file_path = Path("tests/working_test_example.py")
    with open(test_file_path, 'w') as f:
        f.write(test_content)
    
    print(f"   âœ… Created {test_file_path}")

def run_working_tests():
    """Run the working test examples"""
    print("ğŸš€ Running working test examples...")
    
    try:
        result = subprocess.run([
            sys.executable, "tests/working_test_example.py"
        ], cwd=".", capture_output=True, text=True, timeout=120)
        
        print("STDOUT:")
        print(result.stdout)
        
        if result.stderr:
            print("STDERR:")
            print(result.stderr)
            
        if result.returncode == 0:
            print("âœ… Working tests passed!")
            return True
        else:
            print(f"âŒ Tests failed with return code {result.returncode}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ Tests timed out")
        return False
    except Exception as e:
        print(f"âŒ Error running tests: {e}")
        return False

def main():
    """Main function to fix test infrastructure"""
    print("ğŸ”§ VANA Test Infrastructure Fix")
    print("=" * 50)
    
    # Change to project root
    os.chdir(Path(__file__).parent)
    
    try:
        # Step 1: Install missing dependencies
        fix_missing_dependencies()
        print()
        
        # Step 2: Fix configuration
        fix_test_config()
        print()
        
        # Step 3: Create working test example
        create_working_test_example()
        print()
        
        # Step 4: Run working tests
        success = run_working_tests()
        print()
        
        if success:
            print("ğŸ‰ Test infrastructure fix completed successfully!")
            print("âœ… Next steps:")
            print("   1. Replace weak test assertions in existing tests")
            print("   2. Add comprehensive tool testing")
            print("   3. Implement security validation tests")
            print("   4. Test real agent coordination")
        else:
            print("âš ï¸ Test infrastructure partially fixed but some issues remain")
            
    except Exception as e:
        print(f"âŒ Fix failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()