# System Architecture

## Core Components
1. **n8n Workflows** - Primary orchestration layer connecting code, memory, LLMs
2. **Korvus Memory API** - Cloud Run service handling embedding and search
3. **Vertex AI** - GOOGLE Gemini models for response and embedding
4. **Supabase** - Structured logs and state via PostgreSQL
5. **Lovable.dev ** - AI code engineer used during development to build system components
6. **Document AI** - OCR for PNG/PDF files, Extracts text for embedding
7. **Lovable UI** - Contains frontend components (generated by Lovable for demos/display, not runtime-connected) AND a backend API bridge (`api_bridge/prompt_router.py`) defining the `/run` endpoint.

## Execution Flow (High-Level)
1. **Trigger:** An event occurs (e.g., file upload, API call to `/run`, scheduled task).
2. **Orchestration (n8n):** The corresponding n8n workflow is triggered.
3. **Agent Selection/Task Definition:** The n8n workflow determines the task and potentially selects the appropriate agent(s) (e.g., Ben for orchestration, specific agent for task).
4. **Context Retrieval (Rhea/Korvus):** The agent (or n8n) calls Korvus `/search` via Rhea to get relevant context/memory.
5. **LLM Execution (Gemini):** The agent constructs the final prompt (task + context) and sends it to Gemini via Vertex AI.
6. **Response Processing (Sage):** The LLM response may be processed, formatted, or summarized by the Sage agent.
7. **Logging/Embedding (Juno/Korvus):** The final action, result, and potentially the response embedding are logged to Supabase (via Juno?) and the vector store (via Korvus `/embed`).
8. **Output:** The final result is returned to the triggering source (e.g., API response, updated state).

*(Note: The exact interaction between the `/run` API endpoint, n8n workflows, and direct agent calls needs further verification in the implementation.)*

## Development Tooling
- Lovable.dev: Secure code generator, not ui or deployed
- VS Code: Augment, RooCode, Cline for fill-in cases 
- Cloud Run: Deployed per service: korvus-server, agent-server
- Vertex AI : textembedding-gecko, chat-bison, text-bison
- Document AI: image to text via OCR processor

## Interaction Map

``@mermaid
graph TD
A[ User Input ] --> A[ Document AI OCR ]
A --> B[ N_n Workflow ]
B --> C( Agent Selection )
C --> D[ Korvus Search ]
C --> E[ Gemini -\ Vertex AI ]
E --> F[Supabase Log ]
E --> G[Korvus Embed + Vector]```
